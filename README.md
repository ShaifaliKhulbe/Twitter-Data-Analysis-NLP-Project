# Twitter Data Analysis: NLP Project

This is a machine learning and natural language processing (NLP) project that uses Twitter data. The project is developed in Python using Google Colab.

## Data

- **Data Source**: The data is scraped from Twitter using the Tweepy API.
- **Data Contents**: The dataset includes tweets, retweets, and quote tweets related to a specific hashtag.
- **Hashtag**: The data was collected for the hashtag #culture.
- **Purpose**: The data is used to perform various NLP tasks.

## NLP Tasks

The project involves a wide range of NLP tasks, including but not limited to:

1. **Top 5 Most Active Accounts**: Identification of the top 5 most active Twitter accounts based on the number of tweets.

2. **Most Popular Tweet**: Determination of the most popular tweet based on engagement metrics.

3. **Total Tweets**: Calculation of the total number of tweets in the dataset.

4. **Sentiment Analysis**: Analysis of the sentiment of the tweets, categorizing them as positive, negative, or neutral.

5. **Sentiment Distribution**: Visualization of the sentiment distribution using a pie chart.

6. **Top 5 Positive and Negative Tweets**: Selection of the top 5 positive and top 5 negative tweets based on sentiment analysis.

7. **Automatic Summarization**: Utilization of the Gensim library for automatic summarization of text.

8. **TL;DR Generation**: Generation of short summaries (TL;DR) for tweets using the GPT-3 language model.

9. **Most Popular Hashtags**: Identification of the most frequently used hashtags in the dataset.

10. **Most Popular Tweeter**: Determination of the user with the highest tweet count.

11. **Overall Sentiment (Emoji to Image)**: Conversion of emojis to corresponding images to depict overall sentiment.

12. **Wordcloud**: Creation of a word cloud to visualize the most common words in the dataset.

13. **Keyword Extraction**: Extraction of keywords using the KeyBert library.

14. **Tweets per Minute**: Presentation of tweet frequency in a bar graph, showing tweets per minute.

15. **Top 5 Most Active Countries and Regions**: Extraction of data using location tags to identify the top 5 most active countries and regions.

16. **Clustering Tweets**: Clustering tweets using word embeddings, Principal Component Analysis (PCA), and KMeans.

17. **Network Graph**: Creation of a network graph to visualize text data from user descriptions using NetworkX.

## Colab Notebooks

To run this project and perform the NLP tasks, you can follow the code and instructions provided in the accompanying Google Colab notebooks.

## Python Libraries Used

- Tweepy (for data scraping)
- Gensim (for text summarization)
- GPT-3 (for TL;DR generation)
- KeyBert (for keyword extraction)
- NetworkX (for network graph creation)
- And various other NLP and data visualization libraries

---
